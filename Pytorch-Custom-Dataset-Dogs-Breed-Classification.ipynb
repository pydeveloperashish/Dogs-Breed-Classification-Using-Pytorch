{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c2a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from skimage import io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d0ee6",
   "metadata": {},
   "source": [
    "# 0) Initializing All The Necessary Dir Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68707937",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dir = 'Dog-Breed-Dataset/'\n",
    "train_path_dir = os.path.join(dataset_path_dir, 'train')\n",
    "test_path_dir = os.path.join(dataset_path_dir, 'test')\n",
    "labels_file_path = os.path.join(dataset_path_dir, 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd52bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dog-Breed-Dataset/labels.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb3830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(labels_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e497ceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['breed'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc224bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev_ashish/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6ebf1",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0592c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 120\n",
    "IN_CHANNELS = 3\n",
    "NUM_CLASSES = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed338a9",
   "metadata": {},
   "source": [
    "# 1) Preparing Our Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee1ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsBreedDataset(Dataset):\n",
    "    def __init__(self, csv_file, train_dir, transform = None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.train_dir = train_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # index = rows, 0 is first column that is image name\n",
    "        # index we dont choose, pytorch do it for us\n",
    "        img_path = os.path.join(self.train_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(f\"{img_path}.jpg\")\n",
    "        \n",
    "        #image = io.imread(f\"{img_path}.jpg\")\n",
    "        \n",
    "        # index = rows, 1 is second column that is labels name\n",
    "        # index we dont choose, pytorch do it for us\n",
    "        \n",
    "        lr = LabelEncoder()\n",
    "        transformed_labels = lr.fit_transform(self.annotations['breed'])\n",
    "        dataset.annotations['breed'] = transformed_labels\n",
    "        \n",
    "        labels = torch.tensor(self.annotations.iloc[index, 1])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d4299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6d6b506",
   "metadata": {},
   "source": [
    "# 2) Preparing Transformations For Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23126094",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size = IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.465,0.406],\n",
    "                        [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4aee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331f58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "828dd6c9",
   "metadata": {},
   "source": [
    "# 2) Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9660c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogsBreedDataset(csv_file = labels_file_path, train_dir = train_path_dir, \n",
    "                           transform = transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2eae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737365de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DogsBreedDataset at 0x7f7629034a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c9f97",
   "metadata": {},
   "source": [
    "# 3) Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22a84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = dataset.__len__() - 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabca8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = random_split(dataset = dataset, lengths = [7000, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d6ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f762903de80>\n",
      "<torch.utils.data.dataset.Subset object at 0x7f762903dac0>\n",
      "7000\n",
      "3222\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print(test_ds)\n",
    "print(len(train_ds))\n",
    "print(len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec35ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39fb0e9",
   "metadata": {},
   "source": [
    "# 4) Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe5594",
   "metadata": {},
   "source": [
    "Now we have already prepared our custom dataset and splited it, now its time to load it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c79f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_ds, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_ds, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdebd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09dfefb",
   "metadata": {},
   "source": [
    "# 5) Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c9c76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained = True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7356903",
   "metadata": {},
   "source": [
    "## 6) Freeze pre-trained model parameter to avoid backpropogation through them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2679732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d95b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Build custom classifier\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
    "                                        ('relu', nn.ReLU()),\n",
    "                                        ('drop', nn.Dropout(p = 0.5)),\n",
    "                                        ('fc2', nn.Linear(5000, NUM_CLASSES)),\n",
    "                                        ('output', nn.Softmax())]))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe0fca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (fc1): Linear(in_features=25088, out_features=5000, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "    (fc2): Linear(in_features=5000, out_features=120, bias=True)\n",
       "    (output): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05389e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfd8e6f",
   "metadata": {},
   "source": [
    "# 7) Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe3ae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.classifier.parameters(), lr = LEARNING_RATE) # passing classifier.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0944b3",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e542124",
   "metadata": {},
   "source": [
    "As Dataset is ready, splitted and loaded in Data Loader, Model is defined, Loss and Optimizer is Ready.\n",
    "So Lets Train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36895ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev_ashish/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()      # Training Mode Activated\n",
    "    \n",
    "    for images, labels in iter(train_loader):      # Iter \"seems\" to be optional\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Reset the optimizer to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # send images to model for training\n",
    "        preds = model(images)\n",
    "        \n",
    "        # Compute Loss\n",
    "        loss = loss_func(preds, labels)\n",
    "        \n",
    "        # Compute Gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Parameters\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc56f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d497236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83392fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev_ashish/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 50 / 7000 with accuracy 0.714286\n",
      "Checking accuracy on Test Data\n",
      "Got 33 / 3222 with accuracy 1.024209\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader == train_loader:\n",
    "        print(\"Checking accuracy on Training Data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on Test Data\")\n",
    "        \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    model.eval()    # go to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():          # Turn off gradients calculation to save memory\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            scores = model(images)\n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == labels).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:2f}\")\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4d095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407dc0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838d97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f531906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764e06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d27bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
